{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SNLI_+_Glove.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ueYbleaF2igP",
        "L6vpbeMv2fEw",
        "-AbC2vBG2YQ5"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYfc7oeX5p2k",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeYK6eZxfZQe",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNixt4eQ69BM",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6WG9lM7cTcN",
        "colab_type": "code",
        "outputId": "67965ecb-79d9-4297-ecd9-625c6084ef06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "%tensorflow_version 1.15"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.15`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VFHCvlFsv4v",
        "colab_type": "code",
        "outputId": "ec651fbe-552a-4703-ee52-e16edd84ddea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "from functools import reduce\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import tarfile\n",
        "import tempfile\n",
        "import numpy as np\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import merge, recurrent, Dense, Input, Dropout, TimeDistributed\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import np_utils\n",
        "import os, re, csv, math, codecs\n",
        "from keras.layers import concatenate, Flatten, Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Dense, Activation, Input, Concatenate,Dot,RepeatVector,TimeDistributed,Multiply,Lambda,Bidirectional, LSTM, Reshape\n",
        "import keras.backend as K\n",
        "from keras.activations import softmax\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras.activations import softmax\n",
        "from keras.callbacks import EarlyStopping, History, ModelCheckpoint\n",
        "np.random.seed(1337)  # for reproducibility"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2XfuuV0piRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorflow_version 1.15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n4Y906tp9Tt",
        "colab_type": "code",
        "outputId": "0eec3fbe-8bd0-4d0b-e3dc-ded2df5378e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-15 10:09:17--  https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94550081 (90M) [application/zip]\n",
            "Saving to: ‘snli_1.0.zip’\n",
            "\n",
            "snli_1.0.zip        100%[===================>]  90.17M  29.4MB/s    in 3.1s    \n",
            "\n",
            "2020-05-15 10:09:20 (29.4 MB/s) - ‘snli_1.0.zip’ saved [94550081/94550081]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYwUK0bvpj5j",
        "colab_type": "code",
        "outputId": "afe76620-d02e-4254-f41d-8841e09900ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!unzip snli_1.0.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  snli_1.0.zip\n",
            "   creating: snli_1.0/\n",
            "  inflating: snli_1.0/.DS_Store      \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/snli_1.0/\n",
            "  inflating: __MACOSX/snli_1.0/._.DS_Store  \n",
            " extracting: snli_1.0/Icon           \n",
            "  inflating: __MACOSX/snli_1.0/._Icon  \n",
            "  inflating: snli_1.0/README.txt     \n",
            "  inflating: __MACOSX/snli_1.0/._README.txt  \n",
            "  inflating: snli_1.0/snli_1.0_dev.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_dev.txt  \n",
            "  inflating: snli_1.0/snli_1.0_test.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_test.txt  \n",
            "  inflating: snli_1.0/snli_1.0_train.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_train.txt  \n",
            "  inflating: __MACOSX/._snli_1.0     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRRqpAHDX0a8",
        "colab_type": "code",
        "outputId": "669cc912-4da5-48dc-ec0a-8dc6e2ce4bea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-15 10:09:34--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-05-15 10:09:34--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-05-15 10:09:34--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.14MB/s    in 6m 31s  \n",
            "\n",
            "2020-05-15 10:16:05 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQTqtrkWX1Oe",
        "colab_type": "code",
        "outputId": "74a9505c-9349-4342-d22f-bbc2b9f8991f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueYbleaF2igP",
        "colab_type": "text"
      },
      "source": [
        "###Funciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16FPaxSVtNm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_tokens_from_binary_parse(parse):\n",
        "    return parse.replace('(', ' ').replace(')', ' ').replace('-LRB-', '(').replace('-RRB-', ')').split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQoyGjZRr_Ib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(fn, limit=None):\n",
        "  raw_data = list(yield_examples(fn=fn, limit=limit))\n",
        "  left = [s1 for _, s1, s2 in raw_data]\n",
        "  right = [s2 for _, s1, s2 in raw_data]\n",
        "  print(max(len(x.split()) for x in left))\n",
        "  print(max(len(x.split()) for x in right))\n",
        "\n",
        "  LABELS = {'contradiction': 0, 'neutral': 1, 'entailment': 2}\n",
        "  Y = np.array([LABELS[l] for l, s1, s2 in raw_data])\n",
        "  Y = np_utils.to_categorical(Y, len(LABELS))\n",
        "\n",
        "  return left, right, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kFEm8G6sFsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def yield_examples(fn, skip_no_majority=True, limit=None):\n",
        "  for i, line in enumerate(open(fn)):\n",
        "    if limit and i > limit:\n",
        "      break\n",
        "    data = json.loads(line)\n",
        "    label = data['gold_label']\n",
        "    s1 = ' '.join(extract_tokens_from_binary_parse(data['sentence1_binary_parse']))\n",
        "    s2 = ' '.join(extract_tokens_from_binary_parse(data['sentence2_binary_parse']))\n",
        "    if skip_no_majority and label == '-':\n",
        "      continue\n",
        "    yield (label, s1, s2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6vpbeMv2fEw",
        "colab_type": "text"
      },
      "source": [
        "###Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IexTATlRzwvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "to_seq = lambda X: pad_sequences(tokenizer.texts_to_sequences(X), maxlen=MAX_LEN)\n",
        "prepare_data = lambda data: (to_seq(data[0]), to_seq(data[1]), data[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AbC2vBG2YQ5",
        "colab_type": "text"
      },
      "source": [
        "###Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbBlJw8poqRU",
        "colab_type": "code",
        "outputId": "b87ec9f4-d541-4ae3-a46b-b089b3129566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "training = get_data('/content/snli_1.0/snli_1.0_train.jsonl')\n",
        "validation = get_data('/content/snli_1.0/snli_1.0_dev.jsonl')\n",
        "test = get_data('/content/snli_1.0/snli_1.0_test.jsonl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "82\n",
            "62\n",
            "59\n",
            "55\n",
            "57\n",
            "30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6ejlDDJ02QP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=\"UNK\")\n",
        "tokenizer = Tokenizer(lower=False, filters='')\n",
        "tokenizer.fit_on_texts(training[0] + training[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMo1429htlCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lowest index from the tokenizer is 1 - we need to include 0 in our vocab count\n",
        "VOCAB = len(tokenizer.word_counts) + 1\n",
        "LABELS = {'contradiction': 0, 'neutral': 1, 'entailment': 2}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejf5BGlq2Kdb",
        "colab_type": "text"
      },
      "source": [
        "### Veamos algunos ejemplos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuKCgYCeAN-S",
        "colab_type": "code",
        "outputId": "02e1b9fd-23bf-4e0d-934e-7b805ad756d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "training[0][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A person on a horse jumps over a broken down airplane .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9b0YsrqAQVp",
        "colab_type": "code",
        "outputId": "2f53c418-191d-460f-cacd-833f7dbd61f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "training[1][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A person is training his horse for a competition .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_YTxPxaARhJ",
        "colab_type": "code",
        "outputId": "e06bb870-b003-48c7-a22b-f83f2308337f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "training[2][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kqp-9_JP2tzo",
        "colab_type": "text"
      },
      "source": [
        "###Prepare dataset - Training, Validation, Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9ASXBrM1saW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 42\n",
        "training = prepare_data(training)\n",
        "validation = prepare_data(validation)\n",
        "test = prepare_data(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UppdZ75Fqhnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  #Ejemplo de prepare"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8jdhtp9auFE",
        "colab_type": "code",
        "outputId": "9cd5e9e4-805f-41ad-ad32-6272f08e1522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "training[0][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    3,   45,    8,\n",
              "          2,  193,  205,   81,    2, 1171,   40,  822,    1], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zur6tZlibL-U",
        "colab_type": "code",
        "outputId": "ec695d7f-ded8-4ec5-b058-638abc80d174",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "training[1][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    3,\n",
              "         45,    5, 1175,   21,  193,   38,    2,  456,    1], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDZvVjQacRhi",
        "colab_type": "code",
        "outputId": "3f411b01-3f11-4638-a166-13926e1709dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "training[2][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmhK5zTXtvZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "to_seq = lambda X: pad_sequences(tokenizer.texts_to_sequences(X), maxlen=MAX_LEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0I-kv7YY639",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prepare_data = lambda data: (to_seq(data[0]), to_seq(data[1]), data[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUh955FY1-SN",
        "colab_type": "code",
        "outputId": "f7c2c2ea-0592-4943-b213-479417343e07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Build model...')\n",
        "print('Vocab size =', VOCAB)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n",
            "Vocab size = 42391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPpeigT13_G9",
        "colab_type": "text"
      },
      "source": [
        "###Load Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "713828dd-aa15-4ad1-eeb4-ec6c176cdd53",
        "id": "t3Mq88R85BkJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#load embeddings\n",
        "#EMBEDDING_DIR = \"/content/drive/My Drive/\"\n",
        "print('loading word embeddings...')\n",
        "embeddings_index = {}\n",
        "f = codecs.open('/content/glove.6B.100d.txt', encoding='utf-8')\n",
        "for line in f:\n",
        "    values = line.rstrip().rsplit(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('found %s word vectors' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading word embeddings...\n",
            "found 400000 word vectors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94sx69Bz3eLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBED_HIDDEN_SIZE = 300\n",
        "# Embedding layer\n",
        "embed = Embedding(VOCAB, EMBED_HIDDEN_SIZE, weights=[embedding_matrix], input_length=MAX_LEN, trainable=False)\n",
        "# A dense layer applied over each sequence point\n",
        "translate = TimeDistributed(Dense(SENT_HIDDEN_SIZE, activation='relu'))\n",
        "# A layer to sum up the sequence of words\n",
        "SumEmbeddings = keras.layers.core.Lambda(lambda x: K.sum(x, axis=1), output_shape=(SENT_HIDDEN_SIZE, ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZiR1VQE4Fa0",
        "colab_type": "text"
      },
      "source": [
        "###Prepare embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ljv5P4Ada1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare embedding matrix\n",
        "embed_dim=100\n",
        "embedding_matrix=np.zeros([VOCAB+4,embed_dim])\n",
        "for word, idx in tokenizer.word_index.items():\n",
        "  if idx <= VOCAB and word in embeddings_index:\n",
        "    embedding_matrix[idx+3,:]=embeddings_index[word]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cij1Ue_B6Jbk",
        "colab_type": "text"
      },
      "source": [
        "###Translate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwV0Ud4M2xkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SENT_HIDDEN_SIZE = 300\n",
        "translate = TimeDistributed(Dense(SENT_HIDDEN_SIZE, activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbLm17A04KXh",
        "colab_type": "text"
      },
      "source": [
        "###Premisas e Hipotesis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivGCviwY29Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB=VOCAB+4\n",
        "premise = Input(shape=(MAX_LEN,), dtype='int32')\n",
        "hypothesis = Input(shape=(MAX_LEN,), dtype='int32')\n",
        "\n",
        "prem = embed(premise)\n",
        "hypo = embed(hypothesis)\n",
        "\n",
        "prem = translate(prem)\n",
        "hypo = translate(hypo)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp2sTKJQhjkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "value_dim=100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5eULAHJ5s79",
        "colab_type": "code",
        "outputId": "8270ff95-fa4f-457a-c2d9-e9eae6a65a95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "training[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(549367, 42)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o_7zu-a4SNI",
        "colab_type": "text"
      },
      "source": [
        "###Inputs and concatenate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m43hyvp6l7v2",
        "colab_type": "code",
        "outputId": "ddb20290-cdac-471c-ed33-f1a95b5792ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "DP = 0.1\n",
        "RNN = recurrent.LSTM\n",
        "# RNN = lambda *args, **kwargs: Bidirectional(recurrent.LSTM(*args, **kwargs))\n",
        "rnn_kwargs = dict(output_dim=SENT_HIDDEN_SIZE, dropout_W=DP, dropout_U=DP)\n",
        "rnn = RNN(return_sequences=False, **rnn_kwargs)\n",
        "#rnn_kwargs = dict(output_dim=SENT_HIDDEN_SIZE, dropout_W=DP, dropout_U=DP)\n",
        "VOCAB=VOCAB+4\n",
        "# 2 pairs of input sentences\n",
        "premise = Input(shape=(MAX_LEN, ), dtype='int32',)\n",
        "hypothesis = Input(shape=(MAX_LEN, ), dtype='int32')\n",
        "# Get the word embeddings for each of these 2 pairs\n",
        "prem = embed(premise)  # [batchsize, Psize, Embedsize]\n",
        "hypo = embed(hypothesis) # [batchsize, Hsize, Embedsize]\n",
        "# Apply the Dense layer\n",
        "prem = translate(prem)\n",
        "hypo = translate(hypo)\n",
        "# Sum up the sequence\n",
        "prem = rnn(prem)\n",
        "hypo = rnn(hypo)\n",
        "prem = BatchNormalization()(prem)\n",
        "hypo = BatchNormalization()(hypo)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(return_sequences=False, units=300, dropout=0.1, recurrent_dropout=0.1)`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tyz6iDfwmoqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combined the 2 sentences\n",
        "joint = concatenate([prem, hypo])\n",
        "joint = Dropout(0.4)(joint)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0WzGNFH4iWZ",
        "colab_type": "text"
      },
      "source": [
        "###Capas Densas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRm4STU5nBEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L2 = 4e-6\n",
        "for i in range(3):\n",
        "        joint = Dense(2 * SENT_HIDDEN_SIZE, activation='relu', kernel_regularizer=l2(L2) if L2 else None)(joint)\n",
        "        joint = Dropout(0.4)(joint)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8QVF1eH6phX",
        "colab_type": "text"
      },
      "source": [
        "###Softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd_hJaB0nnBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = Dense(len(LABELS), activation='softmax')(joint)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylnVWg6d6u54",
        "colab_type": "text"
      },
      "source": [
        "###Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDURJtsd6vet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[premise, hypothesis], outputs=pred)\n",
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhKF4eAfnz7l",
        "colab_type": "code",
        "outputId": "3dbd8242-21ed-4749-d775-c2cabd1aeeac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 42)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            (None, 42)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 42, 300)      12717300    input_5[0][0]                    \n",
            "                                                                 input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 42, 300)      90300       embedding_1[2][0]                \n",
            "                                                                 embedding_1[3][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 300)          721200      time_distributed_2[2][0]         \n",
            "                                                                 time_distributed_2[3][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 300)          1200        lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 300)          1200        lstm_1[1][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 600)          0           batch_normalization_1[0][0]      \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 600)          0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 600)          360600      dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 600)          0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 600)          360600      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 600)          0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 600)          360600      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 600)          0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 3)            1803        dropout_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 14,614,803\n",
            "Trainable params: 1,896,303\n",
            "Non-trainable params: 12,718,500\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa1mhWhWn4hq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping, History, ModelCheckpoint\n",
        "_, tmpfn = tempfile.mkstemp()\n",
        "BATCH_SIZE = 512\n",
        "MAX_EPOCHS = 5\n",
        "# Save the best model during validation and bail out of training early if we're not improving\n",
        "callbacks = [#EarlyStopping(patience=PATIENCE),\n",
        "        ModelCheckpoint(tmpfn, save_best_only=True, save_weights_only=True),\n",
        "        History(),\n",
        "    ]\n",
        "#model.fit(\n",
        " #       [training[0], training[1]],\n",
        " #       training[2],\n",
        "  #      batch_size=BATCH_SIZE,\n",
        "  #      epochs=MAX_EPOCHS,\n",
        "  #      validation_data=([validation[0], validation[1]], validation[2]),\n",
        "   #     callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaYO85f1jV2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fmPjivOWCpg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPL7axBVaydA",
        "colab_type": "code",
        "outputId": "35801c7b-63e9-4228-e69d-008759488cf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model = load_model('model.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B6NG-Mx5XHs",
        "colab_type": "text"
      },
      "source": [
        "###Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttUB5QMP5T_m",
        "colab_type": "code",
        "outputId": "e3cfbd2f-93b0-4153-fe09-f44c2698eb3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Restore the best found model during validation\n",
        "#model.load_weights(tmpfn)\n",
        "\n",
        "loss, acc = model.evaluate([test[0], test[1]], test[2], batch_size=BATCH_SIZE)\n",
        "print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss, acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9824/9824 [==============================] - 29s 3ms/step\n",
            "Test loss / test accuracy = 0.6884 / 0.7211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QLmIxG_GMJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict = model.predict([test[0], test[1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4d6mKHiewhb",
        "colab_type": "code",
        "outputId": "9f2b734a-9b58-4691-c833-61a7b94e0846",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "predict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.3099998 , 0.4193015 , 0.2706987 ],\n",
              "       [0.19894674, 0.36704957, 0.4340037 ],\n",
              "       [0.28794542, 0.25216246, 0.45989218],\n",
              "       ...,\n",
              "       [0.9822329 , 0.01034008, 0.00742698],\n",
              "       [0.07046628, 0.1640845 , 0.76544917],\n",
              "       [0.18254942, 0.50951105, 0.3079395 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0a9UV4GhE_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_classes = predict.argmax(axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGwS_A1RhJJa",
        "colab_type": "code",
        "outputId": "13bbbb78-88c7-4b8b-88c0-3ec979dc2034",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len\n",
        "len(y_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9824"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    }
  ]
}